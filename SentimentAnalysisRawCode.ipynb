{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "SentimentAnalysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "efyTtfc_oJkh"
      },
      "source": [
        "## 1. Adding imports & installing neccessay packages ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GaVIBWlyoKz3",
        "outputId": "09397fbf-902d-4115-8fcb-aeeab2b6e974",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "### run this if using google colab to mount google drive as local storage\n",
        "\n",
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "repo_path = '/content/gdrive/My Drive/colab/NLP/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sdBgdze84r8s",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import collections\n",
        "%matplotlib inline\n",
        "\n",
        "# Import modules to calculate accuracy and confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLttTMckfNa_",
        "colab_type": "text"
      },
      "source": [
        "## 2. Loading Data ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w9EA4jMv4ywO",
        "outputId": "504c17b3-e702-4ebf-9211-b2df6cb3ebe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "### run below 2 lines of code for setting train & test data path on google colab\n",
        "'''\n",
        "trainData = os.path.join(repo_path, 'data/sentiment140_160k_tweets_train.csv')\n",
        "testData = os.path.join(repo_path, 'data/sentiment140_test.csv')\n",
        "'''\n",
        "\n",
        "### run below 3 lines of code for setting train & test data path on local machine\n",
        "DATA = './data/'\n",
        "trainData = DATA + 'sentiment140_160k_tweets_train.csv'\n",
        "testData =  DATA + 'sentiment140_test.csv'\n",
        "\n",
        "train = pd.read_csv(trainData)\n",
        "test = pd.read_csv(testData)\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>1978186076</td>\n",
              "      <td>ceruleanbreeze</td>\n",
              "      <td>@nocturnalie Anyway, and now Abby and I share ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p</td>\n",
              "      <td>1994697891</td>\n",
              "      <td>enthusiasticjen</td>\n",
              "      <td>@JoeGigantino Few times I'm trying to leave co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>2191885992</td>\n",
              "      <td>LifeRemixed</td>\n",
              "      <td>@AngieGriffin Good Morning Angie  I'll be in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>1753662211</td>\n",
              "      <td>lovemandy</td>\n",
              "      <td>had a good day driving up mountains, visiting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p</td>\n",
              "      <td>2177442789</td>\n",
              "      <td>_LOVELYmanu</td>\n",
              "      <td>downloading some songs  i love lady GaGa.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target  ...                                               text\n",
              "0      p  ...  @nocturnalie Anyway, and now Abby and I share ...\n",
              "1      p  ...  @JoeGigantino Few times I'm trying to leave co...\n",
              "2      p  ...  @AngieGriffin Good Morning Angie  I'll be in t...\n",
              "3      p  ...  had a good day driving up mountains, visiting ...\n",
              "4      p  ...          downloading some songs  i love lady GaGa.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "DE0NVFR9s4o4"
      },
      "source": [
        "Looking at distribution of *'positives'* & *'negatives'* samples in train dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MF2-MSXFoJkr",
        "outputId": "78cc2118-a039-4378-9e39-1e558aabf88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "collections.Counter(train['target'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'n': 79985, 'p': 80000})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vwyLXx_moJks",
        "outputId": "56ffdb0a-b964-4583-8773-c5dcbbf49e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "train.groupby('target').size().plot(kind='bar')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f669030f4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niytViA+oAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyHV7gCCxCpO",
        "colab_type": "text"
      },
      "source": [
        "We will find that it is a relatively well-balanced dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RK3QPUnbUFq",
        "colab_type": "text"
      },
      "source": [
        "## 3. Data (Text) Preprocessing ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N_p8SQxQMKrq",
        "colab": {}
      },
      "source": [
        "### mapping a dictionary of apostrophe words\n",
        "\n",
        "appos = {\n",
        "\"aren't\" : \"are not\",\n",
        "\"can't\" : \"cannot\",\n",
        "\"cant\" : \"cannot\",\n",
        "\"couldn't\" : \"could not\",\n",
        "\"didn't\" : \"did not\",\n",
        "\"doesn't\" : \"does not\",\n",
        "\"don't\" : \"do not\",\n",
        "\"hadn't\" : \"had not\",\n",
        "\"hasn't\" : \"has not\",\n",
        "\"haven't\" : \"have not\",\n",
        "\"he'd\" : \"he would\",\n",
        "\"he'll\" : \"he will\",\n",
        "\"he's\" : \"he is\",\n",
        "\"i'd\" : \"I would\",\n",
        "\"i'd\" : \"I had\",\n",
        "\"i'll\" : \"I will\",\n",
        "\"i'm\" : \"I am\",\n",
        "\"im\" : \"I am\",\n",
        "\"isn't\" : \"is not\",\n",
        "\"it's\" : \"it is\",\n",
        "\"it'll\":\"it will\",\n",
        "\"i've\" : \"I have\",\n",
        "\"let's\" : \"let us\",\n",
        "\"mightn't\" : \"might not\",\n",
        "\"mustn't\" : \"must not\",\n",
        "\"shan't\" : \"shall not\",\n",
        "\"she'd\" : \"she would\",\n",
        "\"she'll\" : \"she will\",\n",
        "\"she's\" : \"she is\",\n",
        "\"shouldn't\" : \"should not\",\n",
        "\"that's\" : \"that is\",\n",
        "\"there's\" : \"there is\",\n",
        "\"they'd\" : \"they would\",\n",
        "\"they'll\" : \"they will\",\n",
        "\"they're\" : \"they are\",\n",
        "\"they've\" : \"they have\",\n",
        "\"we'd\" : \"we would\",\n",
        "\"we're\" : \"we are\",\n",
        "\"weren't\" : \"were not\",\n",
        "\"we've\" : \"we have\",\n",
        "\"what'll\" : \"what will\",\n",
        "\"what're\" : \"what are\",\n",
        "\"what's\" : \"what is\",\n",
        "\"what've\" : \"what have\",\n",
        "\"where's\" : \"where is\",\n",
        "\"who'd\" : \"who would\",\n",
        "\"who'll\" : \"who will\",\n",
        "\"who're\" : \"who are\",\n",
        "\"who's\" : \"who is\",\n",
        "\"who've\" : \"who have\",\n",
        "\"won't\" : \"will not\",\n",
        "\"wouldn't\" : \"would not\",\n",
        "\"you'd\" : \"you would\",\n",
        "\"you'll\" : \"you will\",\n",
        "\"you're\" : \"you are\",\n",
        "\"you've\" : \"you have\",\n",
        "\"'re\": \" are\",\n",
        "\"wasn't\": \"was not\",\n",
        "\"we'll\":\" will\",\n",
        "\"didn't\": \"did not\",\n",
        "\"gg\" : \"going\"\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7IbqS4m-4-EX",
        "outputId": "d8eb63af-ea6f-434a-b6a4-e49b1422b4cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import re\n",
        "\n",
        "def preprocess_text(sentence):\n",
        "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','', sentence['text'])\n",
        "    text = re.sub('@[^\\s]+','', text)\n",
        "    text = text.lower().split()\n",
        "    reformed = [appos[word] if word in appos else word for word in text]\n",
        "    reformed = \" \".join(reformed) \n",
        "    text = re.sub('&[^\\s]+;', '', reformed)\n",
        "    text = re.sub('[^a-zA-Zа-яА-Я1-9]+', ' ', text)\n",
        "    text = re.sub(' +',' ', text)\n",
        "    #text = re.sub(' [\\w] ', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "preprocess = train\n",
        "preprocess['ugc'] = preprocess.apply(preprocess_text, axis=1)\n",
        "\n",
        "preprocess.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>ugc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>1978186076</td>\n",
              "      <td>ceruleanbreeze</td>\n",
              "      <td>@nocturnalie Anyway, and now Abby and I share ...</td>\n",
              "      <td>anyway and now abby and i share all our crops ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p</td>\n",
              "      <td>1994697891</td>\n",
              "      <td>enthusiasticjen</td>\n",
              "      <td>@JoeGigantino Few times I'm trying to leave co...</td>\n",
              "      <td>few times I am trying to leave comments in you...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>2191885992</td>\n",
              "      <td>LifeRemixed</td>\n",
              "      <td>@AngieGriffin Good Morning Angie  I'll be in t...</td>\n",
              "      <td>good morning angie I will be in the atl july 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>1753662211</td>\n",
              "      <td>lovemandy</td>\n",
              "      <td>had a good day driving up mountains, visiting ...</td>\n",
              "      <td>had a good day driving up mountains visiting k...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p</td>\n",
              "      <td>2177442789</td>\n",
              "      <td>_LOVELYmanu</td>\n",
              "      <td>downloading some songs  i love lady GaGa.</td>\n",
              "      <td>downloading some songs i love lady gaga</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target  ...                                                ugc\n",
              "0      p  ...  anyway and now abby and i share all our crops ...\n",
              "1      p  ...  few times I am trying to leave comments in you...\n",
              "2      p  ...  good morning angie I will be in the atl july 8...\n",
              "3      p  ...  had a good day driving up mountains visiting k...\n",
              "4      p  ...            downloading some songs i love lady gaga\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIgTKGb6d-FM",
        "colab_type": "text"
      },
      "source": [
        "## 4. Sentiment Analysis using Lexicon-based Method\n",
        "\n",
        "There are two types of lexicon-based sentiment analyzing approcaches - _Polarity_ and _Valence_ based.\n",
        "\n",
        "_VADER_ is a _VALENCE_ based sentiment analyzer.\n",
        "\n",
        "*Valence*-based approach taken into consideration the \"intensity\" of a word as opposed to only the polarity (+ve or -ve). For example, \"Great\" is treated as more +ve as opposed to \"Good\".\n",
        "\n",
        "References:\n",
        "http://comp.social.gatech.edu/papers/icwsm14.vader.hutto.pdf\n",
        "\n",
        "Scale for the classification model used base on compound value:\n",
        "\n",
        "1. Positive = >=0\n",
        "2. Negative = <0\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YLqIV4RboJke",
        "outputId": "dcf1cc5c-ee5a-4cd3-c28c-831c1c99066b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 1.4MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWKFFV8EeVF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7dkyNuafoJkv",
        "colab": {}
      },
      "source": [
        "def print_sentiment_scores(ugc):\n",
        "    snt = analyzer.polarity_scores(ugc['ugc'])  # Calling the polarity analyzer\n",
        "    return snt['compound']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HPIkzZFRoJky",
        "outputId": "2437dfe5-c681-4c77-e72c-f7921f63c459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "compound = train\n",
        "compound['VADER']=compound.apply(print_sentiment_scores, axis=1)\n",
        "\n",
        "compound.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>ugc</th>\n",
              "      <th>VADER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>1978186076</td>\n",
              "      <td>ceruleanbreeze</td>\n",
              "      <td>@nocturnalie Anyway, and now Abby and I share ...</td>\n",
              "      <td>anyway and now abby and i share all our crops ...</td>\n",
              "      <td>0.6361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p</td>\n",
              "      <td>1994697891</td>\n",
              "      <td>enthusiasticjen</td>\n",
              "      <td>@JoeGigantino Few times I'm trying to leave co...</td>\n",
              "      <td>few times I am trying to leave comments in you...</td>\n",
              "      <td>-0.0258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>2191885992</td>\n",
              "      <td>LifeRemixed</td>\n",
              "      <td>@AngieGriffin Good Morning Angie  I'll be in t...</td>\n",
              "      <td>good morning angie I will be in the atl july 8...</td>\n",
              "      <td>0.4404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>1753662211</td>\n",
              "      <td>lovemandy</td>\n",
              "      <td>had a good day driving up mountains, visiting ...</td>\n",
              "      <td>had a good day driving up mountains visiting k...</td>\n",
              "      <td>0.7717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p</td>\n",
              "      <td>2177442789</td>\n",
              "      <td>_LOVELYmanu</td>\n",
              "      <td>downloading some songs  i love lady GaGa.</td>\n",
              "      <td>downloading some songs i love lady gaga</td>\n",
              "      <td>0.6369</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target         ids  ...                                                ugc   VADER\n",
              "0      p  1978186076  ...  anyway and now abby and i share all our crops ...  0.6361\n",
              "1      p  1994697891  ...  few times I am trying to leave comments in you... -0.0258\n",
              "2      p  2191885992  ...  good morning angie I will be in the atl july 8...  0.4404\n",
              "3      p  1753662211  ...  had a good day driving up mountains visiting k...  0.7717\n",
              "4      p  2177442789  ...            downloading some songs i love lady gaga  0.6369\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSbUIvdwjcxp",
        "colab_type": "code",
        "outputId": "37443950-8c9c-47c6-a0bf-eea747bde027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confusion_matrix(compound['target'], compound['predict'])\n",
        "accuracy_score(compound['target'], compound['predict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6673063099665594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qNBHyZmzoJlA",
        "colab": {}
      },
      "source": [
        "def custom_predict(ugc):\n",
        "    snt = analyzer.polarity_scores(ugc['ugc'])  # Calling the polarity analyzer\n",
        "    if snt['neg'] > snt['pos']:\n",
        "        return 'n'\n",
        "    elif snt['pos'] > snt['neg']:\n",
        "        return 'p'\n",
        "    else:\n",
        "        return 'p'\n",
        "\n",
        "vader = train\n",
        "vader['predict']=vader.apply(custom_predict, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFFGWlghjFEn",
        "colab_type": "code",
        "outputId": "ef2feb51-ffd7-40df-a099-2fb1bd25cf58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "confusion_matrix(vader['target'], vader['predict'])\n",
        "accuracy_score(vader['target'], vader['predict'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6673063099665594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJMMxEVwlSve",
        "colab_type": "text"
      },
      "source": [
        "## 5. Sentiment Analysis using Machine Learning-based Method: Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZKoC2XTmL6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import feature engineering modules and test_train_split\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "#Import classification algorithm\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "#Import modules to calculate accuracy and confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcHkF86B1os5",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes with TF-IDF on original text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VOZ1ylYkoJlN",
        "outputId": "93408788-e0f5-4a6a-f479-d7fe546514af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,3),max_features=20000,stop_words='english') \n",
        "X = tv.fit_transform(train['text'])\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, train['target'],\n",
        "                                               test_size = 0.2, shuffle=True)\n",
        "\n",
        "nb = MultinomialNB(alpha=6.5, fit_prior=False)\n",
        "nb.fit(Xtrain,ytrain)\n",
        "pred = nb.predict(Xtest)\n",
        "\n",
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.753820670687877\n",
            "[[12287  3768]\n",
            " [ 4109 11833]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.75      0.77      0.76     16055\n",
            "           p       0.76      0.74      0.75     15942\n",
            "\n",
            "    accuracy                           0.75     31997\n",
            "   macro avg       0.75      0.75      0.75     31997\n",
            "weighted avg       0.75      0.75      0.75     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVBTTDSF2EdH",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes with TF-IDF on pre-processed text data - achieved very minimal accuracy improvement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d47IpXgy778",
        "colab_type": "code",
        "outputId": "e34e3f01-480e-47c2-d537-9a2a5339785b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,3),max_features=20000,stop_words='english') \n",
        "X = tv.fit_transform(preprocess['ugc'])\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)\n",
        "\n",
        "nb = MultinomialNB(alpha=6.5, fit_prior=False)\n",
        "nb.fit(Xtrain,ytrain)\n",
        "pred = nb.predict(Xtest)\n",
        "\n",
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7545707410069694\n",
            "[[12184  3730]\n",
            " [ 4123 11960]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.75      0.77      0.76     15914\n",
            "           p       0.76      0.74      0.75     16083\n",
            "\n",
            "    accuracy                           0.75     31997\n",
            "   macro avg       0.75      0.75      0.75     31997\n",
            "weighted avg       0.75      0.75      0.75     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DA7VwiTx1Jl",
        "colab_type": "text"
      },
      "source": [
        "Naive Bayes with Grid Search Hyperparameter Tuning & 10-Fold Cross Validation - achieving higher accuracy over the mdoel without hyperparameter tuning "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3ZhKLhuwACL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', MultinomialNB())])\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__alpha': [1, 1e-1, 1e-2]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfDagPpA2pm2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(train['text'], train['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeQV2DTR2wsM",
        "colab_type": "code",
        "outputId": "e034bf72-4d2b-41b9-ca73-6085f80b202c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clf = GridSearchCV(text_clf, tuned_parameters, cv=10)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, clf.predict(x_test), digits=4))\n",
        "print(accuracy_score(y_test, clf.predict(x_test)))\n",
        "print(confusion_matrix(y_test, clf.predict(x_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n     0.7525    0.8386    0.7932     15876\n",
            "           p     0.8209    0.7284    0.7719     16121\n",
            "\n",
            "    accuracy                         0.7831     31997\n",
            "   macro avg     0.7867    0.7835    0.7825     31997\n",
            "weighted avg     0.7870    0.7831    0.7825     31997\n",
            "\n",
            "0.7830734131324811\n",
            "[[13314  2562]\n",
            " [ 4379 11742]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XA9m-gjwBfhO",
        "colab": {}
      },
      "source": [
        "# x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "x_train, x_test, y_train, y_test = train_test_split(preprocess['ugc'], preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWyKpRyRwZ9v",
        "colab_type": "code",
        "outputId": "8c442c6d-fae4-451c-d1e7-f9ab90ecb929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clf = GridSearchCV(text_clf, tuned_parameters, cv=10)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, clf.predict(x_test), digits=4))\n",
        "print(accuracy_score(y_test, clf.predict(x_test)))\n",
        "print(confusion_matrix(y_test, clf.predict(x_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n     0.7571    0.8380    0.7955     16035\n",
            "           p     0.8177    0.7299    0.7713     15962\n",
            "\n",
            "    accuracy                         0.7841     31997\n",
            "   macro avg     0.7874    0.7840    0.7834     31997\n",
            "weighted avg     0.7873    0.7841    0.7834     31997\n",
            "\n",
            "0.7840735068912711\n",
            "[[13438  2597]\n",
            " [ 4312 11650]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9CIcLBrZOGAV",
        "outputId": "9e4f6a6e-1e01-48f5-bbf1-3dc02d16a86d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best Score: \", clf.best_score_)\n",
        "print(\"Best Params: \", clf.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.7837531643591586\n",
            "Best Params:  {'clf__alpha': 0.1, 'tfidf__norm': 'l1', 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z3gTB914oCOi",
        "outputId": "f8115d58-d462-4562-8d34-a02d239456f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import files ### remove this line of code if not using colab\n",
        "\n",
        "test['ugc'] = test.apply(preprocess_text, axis=1)\n",
        "y_kaggle = clf.predict((test['ugc']))\n",
        "test['target'] = pd.DataFrame(y_kaggle.tolist())\n",
        "test[['target', 'ids']].to_csv(\"nb_submission.csv\", index=False)\n",
        "\n",
        "files.download('nb_submission.csv') ### remove this line of code if not using colab\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ncv = TfidfVectorizer(ngram_range=(1,2)) \\nX = tv.fit_transform(train[\\'text\\'])\\n\\ny_kaggle = clf.predict(tv.transform(test[\\'text\\']))\\ntest[\\'target\\'] = pd.DataFrame(y_kaggle.tolist())\\ntest[[\\'target\\', \\'ids\\']].to_csv(\"nb_submission.csv\", index=False)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AKv-eAiCCVrr",
        "outputId": "4977d6d7-68d3-4284-c8ff-2ddde3643a7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "clf = GridSearchCV(text_clf, tuned_parameters, cv=10)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, clf.predict(x_test), digits=4))\n",
        "print(accuracy_score(y_test, clf.predict(x_test)))\n",
        "print(confusion_matrix(y_test, clf.predict(x_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n     0.7734    0.8187    0.7954     16002\n",
            "           p     0.8073    0.7600    0.7829     15995\n",
            "\n",
            "    accuracy                         0.7894     31997\n",
            "   macro avg     0.7904    0.7893    0.7892     31997\n",
            "weighted avg     0.7904    0.7894    0.7892     31997\n",
            "\n",
            "0.7893552520548801\n",
            "[[13101  2901]\n",
            " [ 3839 12156]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qQipVBPD4an",
        "colab_type": "text"
      },
      "source": [
        "## 6. Sentiment Analysis using Machine Learning-based Method: Linear SVM ##\n",
        "with Grid Search Hyperparameter Tuning & 10-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0_tbWb-VxDD",
        "colab": {}
      },
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer()),\n",
        "                     ('tfidf', TfidfTransformer()),\n",
        "                     ('clf', LinearSVC())])\n",
        "tuned_parameters = {\n",
        "    'vect__ngram_range': [(1, 2), (1, 3), (1, 4)],\n",
        "    'tfidf__use_idf': (True, False),\n",
        "    #'tfidf__norm': ('l1', 'l2'),\n",
        "    'clf__tol': [1, 1e-1, 1e-2, 1e-3]\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "28O0StJlXkeF",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(preprocess['ugc'], preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Av0cZhk0XwAj",
        "outputId": "9ba907ca-4765-4b60-97ed-cc9558273fe8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "clf = GridSearchCV(text_clf, tuned_parameters, cv=10)\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "print(classification_report(y_test, clf.predict(x_test), digits=4))\n",
        "print(accuracy_score(y_test, clf.predict(x_test)))\n",
        "print(confusion_matrix(y_test, clf.predict(x_test)))\n",
        "\n",
        "print(\"Best Score: \", clf.best_score_)\n",
        "print(\"Best Params: \", clf.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n     0.7939    0.8293    0.8112     15870\n",
            "           p     0.8243    0.7882    0.8058     16127\n",
            "\n",
            "    accuracy                         0.8086     31997\n",
            "   macro avg     0.8091    0.8087    0.8085     31997\n",
            "weighted avg     0.8092    0.8086    0.8085     31997\n",
            "\n",
            "0.8085758039816233\n",
            "[[13161  2709]\n",
            " [ 3416 12711]]\n",
            "Best Score:  0.8010751007906991\n",
            "Best Params:  {'clf__tol': 0.1, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 4)}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aCpfQMf-wrUd",
        "colab": {}
      },
      "source": [
        "from google.colab import files ### remove this line of code if not using colab\n",
        "\n",
        "test['ugc'] = test.apply(preprocess_text, axis=1)\n",
        "y_kaggle = clf.predict((test['ugc']))\n",
        "test['target'] = pd.DataFrame(y_kaggle.tolist())\n",
        "test[['target', 'ids']].to_csv(\"l_svm_submission.csv\", index=False)\n",
        "\n",
        "files.download('l_svm_submission.csv') ### remove this line of code if not using colab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vCs98OVEgj0",
        "colab_type": "text"
      },
      "source": [
        "## 7. Sentiment Analysis using Machine Learning-based Method: XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yUevtH9biAdO",
        "outputId": "43edaf78-25e9-4591-ef33-25ccda630185",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cb0xoyjMHIS-",
        "colab": {}
      },
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,2), max_features=20000, stop_words='english', min_df=.0025, max_df=0.25) \n",
        "X = tv.fit_transform(preprocess['ugc'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y-eBkJV_O-l3",
        "colab": {}
      },
      "source": [
        "xgb = XGBClassifier(max_depth=10, n_estimators=400, learning_rate=0.3, objective='binary:logistic')\n",
        "xgb.fit(x_train, y_train)\n",
        "pred = xgb.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GRMCIceRPLww",
        "outputId": "0ec2ce37-0d8c-43e8-cfa1-2aad0daa6f51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(accuracy_score(y_test, pred))\n",
        "print(confusion_matrix(y_test, pred))\n",
        "print(classification_report(y_test, pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7501015720223771\n",
            "[[11302  4860]\n",
            " [ 3136 12699]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.78      0.70      0.74     16162\n",
            "           p       0.72      0.80      0.76     15835\n",
            "\n",
            "    accuracy                           0.75     31997\n",
            "   macro avg       0.75      0.75      0.75     31997\n",
            "weighted avg       0.75      0.75      0.75     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDT1ONw8GvGU",
        "colab_type": "text"
      },
      "source": [
        "## 8. Sentiment Analysis using Machine Learning-based Method: Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_icbqVaYLQeT",
        "colab": {}
      },
      "source": [
        "tv = TfidfVectorizer(ngram_range=(1,2), max_features=20000, stop_words='english') \n",
        "X = tv.fit_transform(preprocess['ugc'])\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IFqeKcrd1KRu",
        "colab": {}
      },
      "source": [
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(Xtrain,ytrain)\n",
        "pred = dt.predict(Xtest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2uKqWWPGKVGX",
        "outputId": "d9d047af-a7df-461b-819b-28173405f15c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6914398224833578\n",
            "[[10944  5018]\n",
            " [ 4855 11180]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.69      0.69      0.69     15962\n",
            "           p       0.69      0.70      0.69     16035\n",
            "\n",
            "    accuracy                           0.69     31997\n",
            "   macro avg       0.69      0.69      0.69     31997\n",
            "weighted avg       0.69      0.69      0.69     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OGMG6dFHSKG",
        "colab_type": "text"
      },
      "source": [
        "## 9. Sentiment Analysis using Machine Learning-based Method: Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LJT0_fUHL4Lo",
        "outputId": "02e908a9-e90c-4c00-d456-07507ba37942",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "rf = RandomForestClassifier()\n",
        "rf.fit(Xtrain,ytrain)\n",
        "pred = rf.predict(Xtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqXkCshsY90j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytm58FehYBbL",
        "colab_type": "text"
      },
      "source": [
        "## 10. Sentiment Analysis using Machine Learning-based Method: Extra Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z_8pboH8Me3c",
        "outputId": "09570b9a-82ce-4d92-f731-f2d0582155c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "etc=ExtraTreesClassifier()\n",
        "etc.fit(Xtrain,ytrain)\n",
        "pred=etc.predict(Xtest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hU6sMYxsMaOh",
        "outputId": "28325a29-8551-4e1f-ffab-95ab61e3cf09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7307872613057474\n",
            "[[11874  4088]\n",
            " [ 4526 11509]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.72      0.74      0.73     15962\n",
            "           p       0.74      0.72      0.73     16035\n",
            "\n",
            "    accuracy                           0.73     31997\n",
            "   macro avg       0.73      0.73      0.73     31997\n",
            "weighted avg       0.73      0.73      0.73     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "HzAOiTWffpxS"
      },
      "source": [
        "## 11. Sentiment Analysis using Machine Learning-based Method: SVC ##\n",
        "\n",
        "_Warning - approximately 3hrs of processing_ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X9Un47UTfo4c",
        "colab": {}
      },
      "source": [
        "#Import feature engineering modules and test_train_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "tv = TfidfVectorizer(ngram_range=(1,3)) \n",
        "X = tv.fit_transform(preprocess['ugc'])\n",
        "\n",
        "Xtrain, Xtest, ytrain, ytest = train_test_split(X, preprocess['target'],\n",
        "                                               test_size = 0.2, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bUPQDM0cgU87",
        "outputId": "5e765f81-b921-4c3f-a31b-11c5d1753af5",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(Xtrain,ytrain)\n",
        "pred = svm.predict(Xtest)\n",
        "\n",
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.805137981685783\n",
            "[[12754  3333]\n",
            " [ 2902 13008]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.81      0.79      0.80     16087\n",
            "           p       0.80      0.82      0.81     15910\n",
            "\n",
            "    accuracy                           0.81     31997\n",
            "   macro avg       0.81      0.81      0.81     31997\n",
            "weighted avg       0.81      0.81      0.81     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x-vIIA5lhPz3",
        "colab": {}
      },
      "source": [
        "# Uncomment and run below line of code if using google colab\n",
        "# from google.colab import files\n",
        "\n",
        "test['ugc'] = test.apply(preprocess_text, axis=1)\n",
        "y_kaggle = svm.predict(tv.transform(test['ugc']))\n",
        "test['target'] = pd.DataFrame(y_kaggle.tolist())\n",
        "test[['target', 'ids']].to_csv(\"svc_submission.csv\", index=False)\n",
        "\n",
        "# Uncommon and run below line of code if using google colab \n",
        "# files.download('svc_submission.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M6IJJkJ8v-h",
        "colab_type": "text"
      },
      "source": [
        "## Text Pre-processing Steps - References ##\n",
        "\n",
        "https://www.topbots.com/text-preprocessing-for-machine-learning-nlp/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRVAAJPcc7-B",
        "colab_type": "text"
      },
      "source": [
        "## Further - Text Preprocessing: Porter Stemmer ##"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AoKwyd006Srm",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import LancasterStemmer\n",
        "\n",
        "#nltk.download('punkt') \n",
        "\n",
        "#create an object of class PorterStemmer\n",
        "porter = PorterStemmer()\n",
        "lancaster=LancasterStemmer()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1uQb561z5ifl",
        "outputId": "ffd2f791-d728-48da-c526-24e1962d2ecd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "def stemSentence(sentence):\n",
        "    token_words = word_tokenize(sentence['ugc'])\n",
        "    stem_sentence = []\n",
        "    for word in token_words:\n",
        "        stem_sentence.append(porter.stem(word))\n",
        "        stem_sentence.append(\" \")\n",
        "    return \"\".join(stem_sentence)\n",
        "  \n",
        "preprocess['stem'] = preprocess.apply(stemSentence, axis=1)\n",
        "preprocess.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "      <th>ids</th>\n",
              "      <th>user</th>\n",
              "      <th>text</th>\n",
              "      <th>ugc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>p</td>\n",
              "      <td>1978186076</td>\n",
              "      <td>ceruleanbreeze</td>\n",
              "      <td>@nocturnalie Anyway, and now Abby and I share ...</td>\n",
              "      <td>anyway and now abbi and i share all our crop w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>p</td>\n",
              "      <td>1994697891</td>\n",
              "      <td>enthusiasticjen</td>\n",
              "      <td>@JoeGigantino Few times I'm trying to leave co...</td>\n",
              "      <td>few time i m tri to leav comment in your blog ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>p</td>\n",
              "      <td>2191885992</td>\n",
              "      <td>LifeRemixed</td>\n",
              "      <td>@AngieGriffin Good Morning Angie  I'll be in t...</td>\n",
              "      <td>good morn angi i ll be in the atl juli 8th 1 t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>p</td>\n",
              "      <td>1753662211</td>\n",
              "      <td>lovemandy</td>\n",
              "      <td>had a good day driving up mountains, visiting ...</td>\n",
              "      <td>had a good day drive up mountain visit kati ea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>p</td>\n",
              "      <td>2177442789</td>\n",
              "      <td>_LOVELYmanu</td>\n",
              "      <td>downloading some songs  i love lady GaGa.</td>\n",
              "      <td>download some song i love ladi gaga</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target  ...                                                ugc\n",
              "0      p  ...  anyway and now abbi and i share all our crop w...\n",
              "1      p  ...  few time i m tri to leav comment in your blog ...\n",
              "2      p  ...  good morn angi i ll be in the atl juli 8th 1 t...\n",
              "3      p  ...  had a good day drive up mountain visit kati ea...\n",
              "4      p  ...               download some song i love ladi gaga \n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MyeZzFgdoJla"
      },
      "source": [
        "## Sentiment Analysis using Support Vector Machine, SVM with GridSearch (Machine Learning-Based)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t9QuBe2moJlc",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "import numpy as np\n",
        "# specify parameters to search & test for\n",
        "parameters = {'fit_prior':(True, False), 'alpha': np.linspace(0.5, 15.5)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2_sx3YSVoJld",
        "outputId": "76108fa9-eb6f-4daa-df95-78b0d6a86967",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "nb=MultinomialNB()\n",
        "clf = GridSearchCV(nb, parameters, cv=5)\n",
        "clf.fit(Xtrain,ytrain)     "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
              "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
              "                                     fit_prior=True),\n",
              "             iid='warn', n_jobs=None,\n",
              "             param_grid={'alpha': array([ 0.5       ,  0.80612245,  1.1122449 ,  1.41836735,  1.7244898 ,\n",
              "        2.03061224,  2.33673469,  2.64285714,  2.94897959,  3.25510204,\n",
              "        3.56122449,  3.86734694,  4.17346939,  4.47959184,  4.78571429,\n",
              "        5.09183673,  5.39795918,  5.704...\n",
              "        8.15306122,  8.45918367,  8.76530612,  9.07142857,  9.37755102,\n",
              "        9.68367347,  9.98979592, 10.29591837, 10.60204082, 10.90816327,\n",
              "       11.21428571, 11.52040816, 11.82653061, 12.13265306, 12.43877551,\n",
              "       12.74489796, 13.05102041, 13.35714286, 13.66326531, 13.96938776,\n",
              "       14.2755102 , 14.58163265, 14.8877551 , 15.19387755, 15.5       ]),\n",
              "                         'fit_prior': (True, False)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "th0XZUWToJlf",
        "outputId": "2fd01d47-1365-4680-a1bb-31a7313bebb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Best Score: \", clf.best_score_)\n",
        "print(\"Best Params: \", clf.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.7563209050848517\n",
            "Best Params:  {'alpha': 5.3979591836734695, 'fit_prior': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-zgINBxZSUav",
        "outputId": "f857ffaa-8efa-4f8e-d638-c3eea3dc9228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "l_svm = LinearSVC()\n",
        "l_svm.fit(Xtrain,ytrain)\n",
        "pred=l_svm.predict(Xtest)\n",
        "\n",
        "print(accuracy_score(ytest,pred))\n",
        "print(confusion_matrix(ytest,pred))\n",
        "print(classification_report(ytest,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7527893239991249\n",
            "[[11689  4273]\n",
            " [ 3637 12398]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           n       0.76      0.73      0.75     15962\n",
            "           p       0.74      0.77      0.76     16035\n",
            "\n",
            "    accuracy                           0.75     31997\n",
            "   macro avg       0.75      0.75      0.75     31997\n",
            "weighted avg       0.75      0.75      0.75     31997\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "22mrTytMSqiL",
        "colab": {}
      },
      "source": [
        "parameters = {'C': np.linspace(1, 10), 'fit_intercept':(True, False)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JlnbCk8dTZw2",
        "outputId": "62faa6bf-537d-4dc3-9636-186143c3f01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "l_svm = LinearSVC()\n",
        "clf = GridSearchCV(l_svm, parameters, cv=5)\n",
        "clf.fit(Xtrain,ytrain)\n",
        "\n",
        "print(\"Best Score: \", clf.best_score_)\n",
        "print(\"Best Params: \", clf.best_params_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Score:  0.7472731818607995\n",
            "Best Params:  {'C': 1.0, 'fit_intercept': True}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
